# spark-aoe

## Pre-requirements
- Python >= 3.7
- Docker
- docker-compose
- npm

## Development Setup
- Create virtualenv
- run `pip install -r requirements.txt`
- run `npm install`

### To patch your local serverless configuration and allow remote debug
- run `bin/patch_debugger`
- Create your vs code configuration in `{PROJECT_ROOT}/.vscode/launch.json`
```
{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: Remote Attach",
            "type": "python",
            "request": "attach",
            "connect": {
                "host": "localhost",
                "port": 5890
            },
            "pathMappings": [
                {
                    "localRoot": "${workspaceFolder}",
                    "remoteRoot": "."
                }
            ]
        }
    ]
}
```


## To start the service in local
- run `docker-compose up`
- run `bin/serve {your-aws-profile}`
    - set `REMOTE_DEBUG_SERVER=vscode` before the serve command to allow remote debug

## Alembic migrations
> To run all these commands is needed to have docker running (we need postgresql running)

- To create a new alembic migration file autogenerated from the models definition
    - run `bin/makemigrations {alias_for_your_migration}`
- To apply the migrations (make effective the changes in thedatabase).
    - run `bin/migrate`

